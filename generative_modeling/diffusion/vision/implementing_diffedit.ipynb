{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMTfEiazX3vVHFQbwrMF9jb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bachaudhry/paper_implementations/blob/main/generative_modeling/diffusion/vision/implementing_diffedit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing DiffEdit**\n",
        "\n",
        "Key Steps:\n",
        "\n",
        "1. Provide paper summary with relevant links.\n",
        "2. List the key steps involved in the DiffEdit implementation.\n",
        "3. Setup SD pipelines based on NB 9b.\n",
        "4. Edit segments to generate masks and outputs.\n",
        "5. Provide fleshed out prose to both explain, while comprehending at the same time, what actually happened.\n",
        "6. Provide a series of examples with properly animated interpolation of Diffusion steps.\n",
        "7. References to other implementations.\n",
        "8. Publish as a blog post."
      ],
      "metadata": {
        "id": "iIrcb5GWNm3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paper Summary"
      ],
      "metadata": {
        "id": "C83b0I2qOaaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key idea behind this paper is:\n",
        "\n",
        "> Semantic image editing is an extension of image generation, with the additional constraint that the generated image should be as similar as possible to a given input image. Current editing methods based on diffusion models usually require to provide a mask, making the task much easier by treating it as a conditional inpainting task. In contrast, our main contribution is able to automatically generate a mask highlighting regions of the input image that need to be edited, by contrasting predictions of a diffusion model conditioned on different text prompts. Moreover, we rely on latent inference to preserve content in those regions of interest and show excellent synergies with mask-based diffusion. DIFFEDIT achieves state-of-the-art editing performance on ImageNet.\n",
        "\n",
        "> In our DIFFEDIT approach, a mask generation module determines which part of the image should be edited, and an encoder infers the latents, to provide inputs to a text-conditional diffusion model which produces the image edit.\n",
        "\n",
        "> The three steps of DIFFEDIT. Step 1: we add noise to the input image, and denoise it: once conditioned on the query text, and once conditioned on a reference text (or unconditionally). We derive a mask based on the difference in the denoising results. Step 2: we encode the input image with DDIM, to estimate the latents corresponding to the input image. Step 3: we perform DDIM decoding conditioned on the text query, using the inferred mask to replace the background with pixel values coming from the encoding process at the corresponding timestep.\n",
        "\n",
        ">"
      ],
      "metadata": {
        "id": "85BWEt7xOgX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Yq6AfVZbjo54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb1MXhy5AX7Z"
      },
      "outputs": [],
      "source": [
        "# Ins"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uOtw6LKnNk1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cvmNdvHINliF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEYjEGoKNlrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xh0AJ61pNlw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2HL3IoNQNl1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVfvTlAINl7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QC3ifZsBNmAj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}